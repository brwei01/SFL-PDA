## About SFL-PDA
Self-supervised federated learning can leverage unlabeled data to alleviate representation-level data heterogeneity but remains limited in addressing label-level imbalance. While pre-trained generative models show promise for augmenting minority-labelled data, their effectiveness diminishes in real-world FL scenarios, where client data is private and must not be exposed to the public. To fill this gap, we propose SFL-PDA (*Self-supervised Federated Learning with Personalized Diffusion Adapter*) to address data heterogeneity at both representation- and label-levels. SFL-PDA designs a lightweight class-conditioned LoRA adapter to finetune a personalized diffusion model as per client requests. In this way, the clientâ€™s diffusion model can effectively capture private, domain-specific characteristics for personalized minority-class data generation, ensuring SFL is collaboratively trained with balanced labeled data and achieves consistent performance.  We evaluate SFL-PDA on two standard benchmarks and one private domain-specific dataset against various state-of-the-art baselines under varying heterogeneity levels. The results demonstrate that SFL-PDA can effectively address data heterogeneity, especially at severe levels. Furthermore, ablation studies confirm that our proposed class-conditioned LoRA adapter can yield up to 28.5% improvements on highly heterogeneous data. Finally, privacy analysis suggests that SFL-PDA entails a reduced risk of privacy leakage.
